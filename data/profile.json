[
  {
    "type": "Personal Profile",
    "name": "RONALD NYASHA KANYEPI",
    "summary": "Data Scientist & Applied AI Engineer with 3+ years of experience in machine learning, applied AI, and data-driven innovation. Focused on building scalable systems, operational efficiency, and actionable insights. Skilled in designing and deploying end-to-end ML pipelines, agentic workflows, RAG-enabled systems, and real-time data solutions using Python, SQL, Spark, and AWS. Experienced in leveraging LLMs, LangGraph, LangChain, and Generative AI to optimize business processes, enable decision intelligence, and deliver measurable impact across financial services, real estate, and enterprise analytics.",
    "contact": {
      "email": "kanyepironald@gmail.com",
      "linkedin": "https://www.linkedin.com/in/ronald-nyasha-kanyepi/",
      "portfolio": "https://ronaldkanyepi.github.io/portfolio-website/",
      "github": "https://github.com/ronaldkanyepi"
    },
    "education": [
      {
        "institution": "EMORY UNIVERSITY",
        "location": "Atlanta, GA",
        "degree": "Master of Science in Business Analytics",
        "graduation_year": 2025,
        "notes": "Graduated with MSBA Rigor Award for proficiency in advanced analytics, statistical modeling, ML deployment, and data engineering to solve complex business problems with clarity, precision, and strategic impact."
      },
      {
        "institution": "UNIVERSITY OF ZIMBABWE",
        "location": "Harare, Zimbabwe",
        "degree": "Bachelor of Business Studies and Computing Science",
        "graduation_year": 2021,
        "notes": "Graduated with First Class Honors and awarded the UZ Book Prize for top academic performance, demonstrating strong foundation in computing, analytics, and business strategy."
      }
    ],
    "certifications": [
      "Microsoft Azure AI Fundamentals",
      "Databricks: Generative AI Fundamentals",
      "Oracle SE 11 Java Developer",
      "Akka Reactive Architecture: Domain Driven Design - Level 2",
      "Akka Reactive Architecture: Introduction to Reactive Systems - Level 2"
    ],
    "professional_experience": [
      {
        "role": "DATA SCIENTIST",
        "company": "Pennybacker Capital - Austin, Texas",
        "dates": "Dec 2024 - May 2025",
        "achievements": [
          "Designed and deployed ML models forecasting quarterly Gross Asset Value (GAV) for a $4B+ real estate portfolio with 1% error (MAPE), mitigating ~$2M in potential losses.",
          "Engineered end-to-end data pipelines integrating 50+ internal and external sources on Databricks for predictive modeling, automated reporting, and risk monitoring.",
          "Developed a sentiment-driven early warning system using Google Reviews to detect operational risks and opportunities across 11 multifamily properties.",
          "Translated complex ML predictions into actionable business strategies using SHAP and LIME, improving executive decision-making."
        ]
      },
      {
        "role": "SENIOR DATA SPECIALIST",
        "company": "AFC Commercial Bank - Harare, Zimbabwe",
        "dates": "Mar 2024 – Jun 2024",
        "achievements": [
          "Led analytics for OK Grand Challenge promotion, increasing POS transactions by 200% across 70+ outlets.",
          "Developed dashboards with Python, Apache Spark, and Dash Plotly to monitor 20,000+ ATM and POS transactions in real-time, enabling rapid operational interventions.",
          "Implemented XGBoost-based churn prediction models, improving retention effectiveness by 25% and reducing customer churn by 15%.",
          "Automated data migration workflows from T24 to IDC Core Banking System, achieving 99.4% accuracy while minimizing downtime."
        ]
      },
      {
        "role": "DATA SPECIALIST",
        "company": "AFC Commercial Bank - Harare, Zimbabwe",
        "dates": "Jun 2022 – Feb 2024",
        "achievements": [
          "Built FastAPI backend integrating RBZ API for CRB, reducing processing time by 40% and enhancing compliance.",
          "Created Kafka-Python ETL pipelines standardizing core banking data for branch-wide KPIs.",
          "Optimized reporting services using Airflow and DBT, automating manual processes and increasing efficiency by 80%.",
          "Modernized a monolithic reconciliation application into microservices with Docker, Kubernetes, FastAPI, and Angular, boosting throughput by 150%."
        ]
      }
    ],
    "technical_capabilities": {
      "Programming & Machine Learning": [
        "Python", "R", "TypeScript", "SQL", "scikit-learn", "Darts", "Statsmodels", "ARIMA/SARIMA",
        "TensorFlow", "PyTorch", "LightGBM", "XGBoost", "CatBoost", "Large Language Models (LLMs)",
        "Retrieval-Augmented Generation (RAG)", "LangGraph", "LangChain", "LlamaIndex",
        "OpenAI APIs", "HuggingFace Transformers", "SHAP", "Optuna", "MCP", "Chainlit"
      ],
      "Data Engineering & MLOps": [
        "Apache Spark", "Kafka", "Airflow", "Docker", "Kubernetes", "dbt", "Great Expectations",
        "AWS S3, Glue, EMR", "REST APIs", "Feature Stores", "CI/CD with GitHub Actions",
        "Model Deployment with FastAPI, MLflow, Chainlit"
      ],
      "Visualization & Analytics": [
        "Dash (Plotly)", "Streamlit", "Tableau", "Power BI", "Excel", "Matplotlib", "Seaborn",
        "Time Series Forecasting", "A/B Testing", "Uplift Modeling", "Segmentation",
        "Deep Exploratory Data Analysis (EDA)"
      ],
      "Cloud, Databases & Storage": [
        "AWS (S3, SageMaker, Redshift)", "Databricks", "PostgreSQL", "SQL Server", "MySQL",
        "DynamoDB", "MongoDB", "DuckDB", "Vector Stores (FAISS, Chroma)", "NoSQL", "ElasticSearch",
        "Parquet", "ORC", "JSON", "Avro"
      ]
    },
    "projects": [
      {
        "project_name": "QueryCraft AI",
        "summary": "Conversational AI platform enabling natural language queries over complex databases, leveraging LangGraph, RAG, and multi-step LLM orchestration for automated SQL generation, validation, execution, and summarization.",
        "my_role_and_achievements": [
          "Built full-stack solution with Next.js frontend, FastAPI backend, Docker/Kubernetes deployment, LangFuse observability, MCP integration, and ZITADEL authentication.",
          "Implemented agentic workflows orchestrating LLM reasoning, schema-aware SQL generation, and automated validation pipelines."
        ],
        "technologies": ["Python", "FastAPI", "Next.js", "Docker", "Kubernetes", "LangGraph", "RAG", "LangFuse", "MCP", "ZITADEL"],
        "source_url": "https://github.com/ronaldkanyepi/PersonalRAG"
      },
      {
        "project_name": "Sports Ticket Sales Forecasting",
        "summary": "Predictive model for Atlanta Braves ticket sales integrating attendance, promotions, and weather data.",
        "my_role_and_achievements": [
          "Achieved 3.3% forecast error using XGBoost and LSTM ensembles.",
          "Optimized feature engineering and model selection pipelines for precise forecasting."
        ],
        "technologies": ["Python", "XGBoost", "LSTM", "Pandas", "NumPy", "Scikit-learn"],
        "source_url": "https://github.com/ronaldkanyepi/Sports-Ticket-Forecasting"
      },
      {
        "project_name": "Log Real-Time Analysis",
        "summary": "High-throughput log aggregation and visualization system handling 60,000 events/sec.",
        "my_role_and_achievements": [
          "Designed Kafka-Spark ETL pipelines and integrated DynamoDB for real-time metrics.",
          "Visualized operational insights using Dash Plotly and deployed scalable architecture via Docker-compose."
        ],
        "technologies": ["Python", "Kafka", "Spark", "DynamoDB", "Dash", "Plotly", "Docker"],
        "source_url": "https://github.com/ronaldkanyepi/Log-Realtime-Analysis"
      },
      {
        "project_name": "Zim Docs OCR-to-JSON Extractor",
        "summary": "Web app converting scanned documents into structured JSON format using vision AI for licenses, passports, and invoices.",
        "my_role_and_achievements": [
          "Built scalable OCR pipeline with Gradio, PyMuPDF, and OpenAI-compatible APIs.",
          "Handled both PDFs and image inputs for structured, machine-readable outputs."
        ],
        "technologies": ["Python", "Gradio", "PyMuPDF", "OpenAI APIs"],
        "source_url": {
          "demo": "https://huggingface.co/spaces/NyashaK/DocOCR2JSON",
          "github": "https://github.com/ronaldkanyepi/docs-ocr-2-json"
        }
      }
    ]
  }
]
